{
  "paragraphs": [
    {
      "text": "val test \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/embAdaptivity/ml_1m/input_data/inputdata.headers\")\n\nval users \u003d test.select(\"userid\").distinct\n\nusers.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/embAdaptivity/dat.ml_1m.users.temp\")",
      "authenticationInfo": {},
      "dateUpdated": "Mar 22, 2017 8:46:26 PM",
      "config": {
        "enabled": true,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1490195766015_-1812823794",
      "id": "20170322-161606_287827792",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "test: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\nusers: org.apache.spark.sql.DataFrame \u003d [userid: int]\n"
      },
      "dateCreated": "Mar 22, 2017 4:16:06 PM",
      "dateStarted": "Mar 22, 2017 6:38:54 PM",
      "dateFinished": "Mar 22, 2017 6:39:07 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val test \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/embAdaptivity/ml_1m/input_data/inputdata.headers\")\n    \nval sample \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/embAdaptivity/ml_1m/dat.ml_1m.users.train\")\n    \nval trainTemp \u003d test.join(sample,test(\"userid\")\u003d\u003d\u003dsample(\"userid\")).drop(sample(\"userid\"))\n\nval train \u003d trainTemp.orderBy(\"timestamp\")\n\ntrain.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/embAdaptivity/ml_1m/dat.train.temp\")\n",
      "authenticationInfo": {},
      "dateUpdated": "Mar 22, 2017 9:13:37 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1490212586640_1095838644",
      "id": "20170322-205626_1532802482",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "test: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\nsample: org.apache.spark.sql.DataFrame \u003d [userid: int]\ntrainTemp: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\ntrain: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\n"
      },
      "dateCreated": "Mar 22, 2017 8:56:26 PM",
      "dateStarted": "Mar 22, 2017 9:13:37 PM",
      "dateFinished": "Mar 22, 2017 9:14:17 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val train \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \",\")\n    .load(\"/data/sidana/embAdaptivity/ml_1m/dat.train\")\nval itemsTrain \u003d train.select(\"itemid\").distinct\nitemsTrain.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/embAdaptivity/ml_1m/dat.ml_1m.items.train\")",
      "authenticationInfo": {},
      "dateUpdated": "Mar 23, 2017 12:55:47 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1490226358367_-1244881637",
      "id": "20170323-004558_1573454614",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "train: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\nitemsTrain: org.apache.spark.sql.DataFrame \u003d [itemid: int]\n"
      },
      "dateCreated": "Mar 23, 2017 12:45:58 AM",
      "dateStarted": "Mar 23, 2017 12:55:47 AM",
      "dateFinished": "Mar 23, 2017 12:56:20 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val test \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/embAdaptivity/ml_1m/input_data/inputdata.headers\")\n    \nval sample \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/embAdaptivity/ml_1m/dat.ml_1m.users.train\")\n\nval newusers \u003d test.select(\"userid\").except(sample.select(\"userid\")).distinct\n\nnewusers.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/embAdaptivity/ml_1m/dat.ml_1m.users.test.temp\")\n\n",
      "authenticationInfo": {},
      "dateUpdated": "Mar 23, 2017 1:34:57 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1490227243412_-670165827",
      "id": "20170323-010043_1952958872",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "test: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\nsample: org.apache.spark.sql.DataFrame \u003d [userid: int]\nnewusers: org.apache.spark.sql.DataFrame \u003d [userid: int]\n"
      },
      "dateCreated": "Mar 23, 2017 1:00:43 AM",
      "dateStarted": "Mar 23, 2017 1:02:55 AM",
      "dateFinished": "Mar 23, 2017 1:03:09 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val test \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/embAdaptivity/ml_1m/input_data/inputdata.headers\")\n\nval trainItems \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \",\")\n    .load(\"/data/sidana/embAdaptivity/ml_1m/dat.ml_1m.items.train\")\n    \nval testUsers \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/embAdaptivity/ml_1m/dat.ml_1m.users.test\")\n    \nval testTempTemp \u003d test.join(testUsers,test(\"userid\")\u003d\u003d\u003dtestUsers(\"userid\")).drop(testUsers(\"userid\"))\n\nval testTemp \u003d testTempTemp.join(trainItems,testTempTemp(\"itemid\")\u003d\u003d\u003dtrainItems(\"itemid\")).drop(trainItems(\"itemid\"))\n\nval testToBeWritten \u003d testTemp.orderBy(\"timestamp\")\n\ntestToBeWritten.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/embAdaptivity/ml_1m/dat.test.temp\")\n\n\n\n\n",
      "authenticationInfo": {},
      "dateUpdated": "Mar 23, 2017 1:34:57 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1490195766017_-1728948533",
      "id": "20170322-161606_22554892",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "test: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\ntrainItems: org.apache.spark.sql.DataFrame \u003d [itemid: int]\ntestUsers: org.apache.spark.sql.DataFrame \u003d [userid: int]\ntestTempTemp: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\ntestTemp: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\ntestToBeWritten: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\n"
      },
      "dateCreated": "Mar 22, 2017 4:16:06 PM",
      "dateStarted": "Mar 23, 2017 1:30:31 AM",
      "dateFinished": "Mar 23, 2017 1:31:40 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "//tests\n\nval test \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \",\")\n    .load(\"/data/sidana/embAdaptivity/ml_1m/dat.test\")\n\n\nval train \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \",\")\n    .load(\"/data/sidana/embAdaptivity/ml_1m/dat.train\")\n    \n\ntrain.select(\"itemid\").distinct.count\ntest.select(\"itemid\").distinct.count\n\ntrain.select(\"userid\").distinct.count\ntest.select(\"userid\").distinct.count\n\ntest.select(\"userid\").except(train.select(\"userid\")).distinct.count\ntest.select(\"itemid\").except(train.select(\"itemid\")).distinct.count\n\n\n",
      "authenticationInfo": {},
      "dateUpdated": "Mar 23, 2017 1:44:23 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1490229031665_984966457",
      "id": "20170323-013031_297469450",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "test: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\ntrain: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\nres9: Long \u003d 3490\nres10: Long \u003d 3448\nres11: Long \u003d 1208\nres12: Long \u003d 4832\nres13: Long \u003d 4832\nres14: Long \u003d 0\n"
      },
      "dateCreated": "Mar 23, 2017 1:30:31 AM",
      "dateStarted": "Mar 23, 2017 1:44:23 AM",
      "dateFinished": "Mar 23, 2017 1:44:46 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1490229847223_1877178899",
      "id": "20170323-014407_648302440",
      "dateCreated": "Mar 23, 2017 1:44:07 AM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "embAdaptivity: ml-1mSubset",
  "id": "2CDEQ1GJA",
  "angularObjects": {
    "2BGHSKCA7": [],
    "2BFMBPKAB": [],
    "2BHKKP27G": [],
    "2BJHJDBK6": [],
    "2BJAQG5W4": [],
    "2BJGSXM37": [],
    "2BFXEV5XZ": [],
    "2BG77RV7M": [],
    "2BF969NNB": [],
    "2BG8QQJNC": [],
    "2BGVG5JP4": [],
    "2BJ5FCP57": [],
    "2BFEDXCTE": [],
    "2BJ8AEWCT": [],
    "2BH9AVVKH": [],
    "2BJ7KKX85": [],
    "2BHKAE8WK": [],
    "2BJ6HN5AY": []
  },
  "config": {
    "looknfeel": "default"
  },
  "info": {}
}