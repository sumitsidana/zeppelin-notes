{
  "paragraphs": [
    {
      "text": "//val seq \u003d Seq(\"offerid\",\"category\",\"merchant\")\n\nval candidates \u003d sqlContext.read\n.format(\"com.databricks.spark.csv\")\n.option(\"header\", \"true\") // Use first line of all files as header\n.option(\"inferSchema\", \"true\") // Automatically infer data types\n.option(\"delimiter\", \"\\t\")\n.load(\"/data/sidana/april_2018_pandor/all/test.users.unique\")\n\nval parquetFileOffers \u003d sqlContext.read\n.format(\"com.databricks.spark.csv\")\n.option(\"header\", \"true\") // Use first line of all files as header\n.option(\"inferSchema\", \"true\") // Automatically infer data types\n.option(\"delimiter\", \"\\t\")\n.load(\"/data/sidana/april_2018_pandor/all/offers.unique\")\n\nval offerViews \u003d  parquetFileOffers.select(\"offerid\").distinct\n\n//val offerClicks \u003d sqlContext.read\n//.format(\"com.databricks.spark.csv\")\n//.option(\"header\", \"true\") // Use first line of all files as header\n//.option(\"inferSchema\", \"true\") // Automatically infer data types\n//.option(\"delimiter\", \",\")\n//.load(\"/data/sidana/recsysBaselines/experiments/debug_ffm/debug_ffm/debug/atleast_two/offerClicks_fr.train\").withColumnRenamed(\"count\",\"offerclickcount\")\n\n\n//val userClicks \u003d sqlContext.read\n//.format(\"com.databricks.spark.csv\")\n//.option(\"header\", \"true\") // Use first line of all files as header\n//.option(\"inferSchema\", \"true\") // Automatically infer data types\n//.option(\"delimiter\", \",\")\n//.load(\"/data/sidana/recsysBaselines/experiments/debug_ffm/debug_ffm/debug/atleast_two/userClicks_fr.train\").withColumnRenamed(\"count\",\"userclickcount\")\n\n//val offerViewsClicks \u003d offerViews.join(offerClicks,Seq(\"offerid\"),\"left_outer\")\n\nval userOfferCartesianProduct \u003d offerViews.join(candidates)\n\n//val userOfferCartesianProductClicks \u003d userOfferCartesianProduct.join(userClicks,Seq(\"userid\"),\"left_outer\").na.fill(0,Seq(\"userclickcount\",\"offerclickcount\"))\n\nval file_rating_temp \u003d userOfferCartesianProduct.withColumn(\"rating\",lit(\"0\"))\n\nval file_rating \u003d file_rating_temp.withColumn(\"timestamp\",lit(\"889396582\"))\n//val file_country \u003d file_rating.withColumn(\"countrycode\",lit(\"fr\"))\n//val file_utcdate \u003d file_country.withColumn(\"utc_date\",lit(\"x\"))\n\n\n//val tempfile \u003d file_utcdate.orderBy(\"utcdate\")\n\n//tempfile.count\n\nval header \u003d \"userid,offerid,rating,timestamp\"\n\nval selectfields \u003d file_rating.select(\"userid\",\"offerid\",\"rating\",\"timestamp\")\n\nval cartesian_product \u003d selectfields.rdd.map(_.mkString(\"\\t\")).mapPartitionsWithIndex((i, iter) \u003d\u003e if (i\u003d\u003d0) (List(header).toIterator ++ iter) else iter)\n\ncartesian_product.coalesce(1,false).saveAsTextFile(\"/data/sidana/april_2018_pandor/all/cartesian_product\")",
      "dateUpdated": "Jun 30, 2018 11:45:29 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1530089328627_177947566",
      "id": "20180627-104848_728652373",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "candidates: org.apache.spark.sql.DataFrame \u003d [userid: int]\nparquetFileOffers: org.apache.spark.sql.DataFrame \u003d [offerid: int]\nofferViews: org.apache.spark.sql.DataFrame \u003d [offerid: int]\nuserOfferCartesianProduct: org.apache.spark.sql.DataFrame \u003d [offerid: int, userid: int]\nfile_rating_temp: org.apache.spark.sql.DataFrame \u003d [offerid: int, userid: int, rating: string]\nfile_rating: org.apache.spark.sql.DataFrame \u003d [offerid: int, userid: int, rating: string, timestamp: string]\nheader: String \u003d userid,offerid,rating,timestamp\nselectfields: org.apache.spark.sql.DataFrame \u003d [userid: int, offerid: int, rating: string, timestamp: string]\ncartesian_product: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[34] at mapPartitionsWithIndex at \u003cconsole\u003e:43\n"
      },
      "dateCreated": "Jun 27, 2018 10:48:48 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "//val seq \u003d Seq(\"offerid\",\"category\",\"merchant\")\n\nval candidates \u003d sqlContext.read\n.format(\"com.databricks.spark.csv\")\n.option(\"header\", \"true\") // Use first line of all files as header\n.option(\"inferSchema\", \"true\") // Automatically infer data types\n.option(\"delimiter\", \"\\t\")\n.load(\"/data/sidana/purch/diversity/baselines/hundredmostpopular/test.users\")\n\nval parquetFileOffers \u003d sqlContext.read\n.format(\"com.databricks.spark.csv\")\n.option(\"header\", \"true\") // Use first line of all files as header\n.option(\"inferSchema\", \"true\") // Automatically infer data types\n.option(\"delimiter\", \"\\t\")\n.load(\"/data/sidana/purch/diversity/baselines/hundredmostpopular/mostpopularitems.txt\")\n\nval offerViews \u003d  parquetFileOffers.select(\"offerId\").distinct\n\nval userOfferCartesianProduct \u003d offerViews.join(candidates)\n\n\nval file_rating \u003d userOfferCartesianProduct.withColumn(\"rating\",lit(\"0\"))\n\nval header \u003d \"userid\\tofferid\\trating\"\n\nval selectfields \u003d file_rating.select(\"userid\",\"offerid\",\"rating\")\n\nval cartesian_product \u003d selectfields.rdd.map(_.mkString(\"\\t\")).mapPartitionsWithIndex((i, iter) \u003d\u003e if (i\u003d\u003d0) (List(header).toIterator ++ iter) else iter)\n\ncartesian_product.saveAsTextFile(\"/data/sidana/purch/diversity/baselines/hundredmostpopular/fm/cartesian_product\")",
      "dateUpdated": "Jun 27, 2018 10:48:48 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1530089328628_176023821",
      "id": "20180627-104848_1395034223",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "candidates: org.apache.spark.sql.DataFrame \u003d [userid: string]\nparquetFileOffers: org.apache.spark.sql.DataFrame \u003d [offerid: bigint]\nofferViews: org.apache.spark.sql.DataFrame \u003d [offerId: bigint]\nuserOfferCartesianProduct: org.apache.spark.sql.DataFrame \u003d [offerId: bigint, userid: string]\nfile_rating: org.apache.spark.sql.DataFrame \u003d [offerId: bigint, userid: string, rating: string]\nheader: String \u003d userid\tofferid\trating\nselectfields: org.apache.spark.sql.DataFrame \u003d [userid: string, offerid: bigint, rating: string]\ncartesian_product: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[34] at mapPartitionsWithIndex at \u003cconsole\u003e:41\n"
      },
      "dateCreated": "Jun 27, 2018 10:48:48 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "parquetFileOffers.count\nofferViews.count",
      "dateUpdated": "Jun 27, 2018 10:48:48 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1530089328628_176023821",
      "id": "20180627-104848_1852449482",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "res3: Long \u003d 100\nres4: Long \u003d 100\n"
      },
      "dateCreated": "Jun 27, 2018 10:48:48 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val cartesian_product \u003d sqlContext.read\n.format(\"com.databricks.spark.csv\")\n.option(\"header\", \"true\") // Use first line of all files as header\n.option(\"inferSchema\", \"true\") // Automatically infer data types\n.option(\"delimiter\", \"\\t\")\n.load(\"/data/sidana/purch/diversity/baselines/hundredmostpopular/cartesian_product\")\n\ncartesian_product.groupBy(\"userid\").count.describe().show",
      "dateUpdated": "Jun 27, 2018 10:48:48 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1530089328628_176023821",
      "id": "20180627-104848_1762621420",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "cartesian_product: org.apache.spark.sql.DataFrame \u003d [userid: string, offerid: bigint, rating: int]\n+-------+-----+\n|summary|count|\n+-------+-----+\n|  count| 9371|\n|   mean|100.0|\n| stddev|  0.0|\n|    min|  100|\n|    max|  100|\n+-------+-----+\n\n"
      },
      "dateCreated": "Jun 27, 2018 10:48:48 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val cartesian_product \u003d sqlContext.read\n.format(\"com.databricks.spark.csv\")\n.option(\"header\", \"true\") // Use first line of all files as header\n.option(\"inferSchema\", \"true\") // Automatically infer data types\n.option(\"delimiter\", \"\\t\")\n.load(\"/data/sidana/april_2018_pandor/all/test.temp.csv\")\n\ncartesian_product.groupBy(\"userid\").count.describe().show",
      "authenticationInfo": {},
      "dateUpdated": "Jul 1, 2018 11:56:11 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1530089328628_176023821",
      "id": "20180627-104848_812266602",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "cartesian_product: org.apache.spark.sql.DataFrame \u003d [userid: int, offerid: int, rating: int, timestamp: int]\n+-------+-----------------+------+\n|summary|           userid| count|\n+-------+-----------------+------+\n|  count|            10066| 10066|\n|   mean|75490.19123783032|9077.0|\n| stddev|52906.36275705513|   0.0|\n|    min|                0|  9077|\n|    max|           177358|  9077|\n+-------+-----------------+------+\n\n"
      },
      "dateCreated": "Jun 27, 2018 10:48:48 AM",
      "dateStarted": "Jul 1, 2018 11:56:12 PM",
      "dateFinished": "Jul 2, 2018 12:26:10 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "//val seq \u003d Seq(\"offerid\",\"category\",\"merchant\")\n\nval candidates \u003d sqlContext.read\n.format(\"com.databricks.spark.csv\")\n.option(\"header\", \"true\") // Use first line of all files as header\n.option(\"inferSchema\", \"true\") // Automatically infer data types\n.option(\"delimiter\", \"\\t\")\n.load(\"/data/sidana/neural_collaborative_filtering/pandor/all/test.users.uniq\")\n\nval parquetFileOffers \u003d sqlContext.read\n.format(\"com.databricks.spark.csv\")\n.option(\"header\", \"true\") // Use first line of all files as header\n.option(\"inferSchema\", \"true\") // Automatically infer data types\n.option(\"delimiter\", \"\\t\")\n.load(\"/data/sidana/neural_collaborative_filtering/pandor/all/offers.uniq\")\n\nval offerViews \u003d  parquetFileOffers.select(\"offerid\").distinct\n\nval userOfferCartesianProduct \u003d offerViews.join(candidates)\n\nval file_rating_temp \u003d userOfferCartesianProduct.withColumn(\"rating\",lit(\"0\"))\n\nval file_rating \u003d file_rating_temp.withColumn(\"timestamp\",lit(\"889396582\"))\n\nval header \u003d \"userid,offerid,rating,timestamp\"\n\nval selectfields \u003d file_rating.select(\"userid\",\"offerid\",\"rating\",\"timestamp\")\n\nval cartesian_product \u003d selectfields.rdd.map(_.mkString(\"\\t\")).mapPartitionsWithIndex((i, iter) \u003d\u003e if (i\u003d\u003d0) (List(header).toIterator ++ iter) else iter)\n\ncartesian_product.coalesce(1,false).saveAsTextFile(\"/data/sidana/neural_collaborative_filtering/pandor/all/cartesian_product\")",
      "authenticationInfo": {},
      "dateUpdated": "Sep 26, 2018 12:44:44 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1530089328628_176023821",
      "id": "20180627-104848_1466480632",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "candidates: org.apache.spark.sql.DataFrame \u003d [userid: int]\nparquetFileOffers: org.apache.spark.sql.DataFrame \u003d [offerid: int]\nofferViews: org.apache.spark.sql.DataFrame \u003d [offerid: int]\nuserOfferCartesianProduct: org.apache.spark.sql.DataFrame \u003d [offerid: int, userid: int]\nfile_rating_temp: org.apache.spark.sql.DataFrame \u003d [offerid: int, userid: int, rating: string]\nfile_rating: org.apache.spark.sql.DataFrame \u003d [offerid: int, userid: int, rating: string, timestamp: string]\nheader: String \u003d userid,offerid,rating,timestamp\nselectfields: org.apache.spark.sql.DataFrame \u003d [userid: int, offerid: int, rating: string, timestamp: string]\ncartesian_product: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[34] at mapPartitionsWithIndex at \u003cconsole\u003e:43\n"
      },
      "dateCreated": "Jun 27, 2018 10:48:48 AM",
      "dateStarted": "Sep 26, 2018 12:44:44 AM",
      "dateFinished": "Sep 26, 2018 12:45:14 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// ncf re-visited\n\nval train \u003d sqlContext.read\n.format(\"com.databricks.spark.csv\")\n.option(\"header\", \"true\") // Use first line of all files as header\n.option(\"inferSchema\", \"true\") // Automatically infer data types\n.option(\"delimiter\", \"\\t\")\n.load(\"/data/sidana/neural_collaborative_filtering/pandor/all/train_all_raw.csv\")\n\nval positiveTrain \u003d train.filter($\"rating\"\u003d\u003d\u003d \"4\")\n\nval offerIds \u003d positiveTrain.select(\"offerid\").distinct\n\nofferIds.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/neural_collaborative_filtering/pandor/all/positive_offer_ids\")\n",
      "authenticationInfo": {},
      "dateUpdated": "Oct 14, 2018 2:44:21 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1539466571180_1821216006",
      "id": "20181013-233611_1812802195",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "train: org.apache.spark.sql.DataFrame \u003d [userid: int, offerid: int, rating: int, timestamp: int]\npositiveTrain: org.apache.spark.sql.DataFrame \u003d [userid: int, offerid: int, rating: int, timestamp: int]\nofferIds: org.apache.spark.sql.DataFrame \u003d [offerid: int]\n"
      },
      "dateCreated": "Oct 13, 2018 11:36:11 PM",
      "dateStarted": "Oct 14, 2018 2:44:21 PM",
      "dateFinished": "Oct 14, 2018 2:44:30 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1539467894157_-952766677",
      "id": "20181013-235814_514066671",
      "dateCreated": "Oct 13, 2018 11:58:14 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "//val seq \u003d Seq(\"offerid\",\"category\",\"merchant\")\n\nval candidates \u003d sqlContext.read\n.format(\"com.databricks.spark.csv\")\n.option(\"header\", \"true\") // Use first line of all files as header\n.option(\"inferSchema\", \"true\") // Automatically infer data types\n.option(\"delimiter\", \"\\t\")\n.load(\"/data/sidana/neural_collaborative_filtering/pandor/all/test.users.unique\")\n\nval parquetFileOffers \u003d sqlContext.read\n.format(\"com.databricks.spark.csv\")\n.option(\"header\", \"true\") // Use first line of all files as header\n.option(\"inferSchema\", \"true\") // Automatically infer data types\n.option(\"delimiter\", \"\\t\")\n.load(\"/data/sidana/neural_collaborative_filtering/pandor/all/pos_offers\")\n\nval offerViews \u003d  parquetFileOffers.select(\"offerid\").distinct\n\nval userOfferCartesianProduct \u003d offerViews.join(candidates)\n\nval file_rating_temp \u003d userOfferCartesianProduct.withColumn(\"rating\",lit(\"0\"))\n\nval file_rating \u003d file_rating_temp.withColumn(\"timestamp\",lit(\"889396582\"))\n\nval header \u003d \"userid,offerid,rating,timestamp\"\n\nval selectfields \u003d file_rating.select(\"userid\",\"offerid\",\"rating\",\"timestamp\")\n\nval cartesian_product \u003d selectfields.rdd.map(_.mkString(\"\\t\")).mapPartitionsWithIndex((i, iter) \u003d\u003e if (i\u003d\u003d0) (List(header).toIterator ++ iter) else iter)\n\ncartesian_product.coalesce(1,false).saveAsTextFile(\"/data/sidana/neural_collaborative_filtering/pandor/all/cartesian_product\")",
      "authenticationInfo": {},
      "dateUpdated": "Oct 14, 2018 2:47:06 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1539466570540_1968959584",
      "id": "20181013-233610_1077660669",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "candidates: org.apache.spark.sql.DataFrame \u003d [userid: int]\nparquetFileOffers: org.apache.spark.sql.DataFrame \u003d [offerid: int]\nofferViews: org.apache.spark.sql.DataFrame \u003d [offerid: int]\nuserOfferCartesianProduct: org.apache.spark.sql.DataFrame \u003d [offerid: int, userid: int]\nfile_rating_temp: org.apache.spark.sql.DataFrame \u003d [offerid: int, userid: int, rating: string]\nfile_rating: org.apache.spark.sql.DataFrame \u003d [offerid: int, userid: int, rating: string, timestamp: string]\nheader: String \u003d userid,offerid,rating,timestamp\nselectfields: org.apache.spark.sql.DataFrame \u003d [userid: int, offerid: int, rating: string, timestamp: string]\ncartesian_product: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[34] at mapPartitionsWithIndex at \u003cconsole\u003e:43\n"
      },
      "dateCreated": "Oct 13, 2018 11:36:10 PM",
      "dateStarted": "Oct 14, 2018 2:47:06 PM",
      "dateFinished": "Oct 14, 2018 2:54:54 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1539466569796_2058221329",
      "id": "20181013-233609_1042175511",
      "dateCreated": "Oct 13, 2018 11:36:09 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1539466569092_1048640215",
      "id": "20181013-233609_775522834",
      "dateCreated": "Oct 13, 2018 11:36:09 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "\n\n",
      "dateUpdated": "Oct 13, 2018 11:36:49 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1537915484074_1297205283",
      "id": "20180926-004444_1616760187",
      "dateCreated": "Sep 26, 2018 12:44:44 AM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "purchBaselinesVer3: Cartesian_Product",
  "id": "2DHBK35TG",
  "angularObjects": {
    "2BJGSXM37": [],
    "2BGHSKCA7": [],
    "2BHKKP27G": [],
    "2BGVG5JP4": [],
    "2BFMBPKAB": [],
    "2BF969NNB": [],
    "2BJAQG5W4": [],
    "2BJHJDBK6": [],
    "2BHKAE8WK": [],
    "2BG8QQJNC": [],
    "2BJ7KKX85": [],
    "2BH9AVVKH": [],
    "2BJ6HN5AY": [],
    "2BFEDXCTE": [],
    "2BJ5FCP57": [],
    "2BJ8AEWCT": [],
    "2BFXEV5XZ": [],
    "2BG77RV7M": []
  },
  "config": {},
  "info": {}
}