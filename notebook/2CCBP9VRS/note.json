{
  "paragraphs": [
    {
      "text": "val data \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/embAdaptivity/ml_1m/input_data/inputdata.headers\")\n\nval users \u003d test.select(\"userid\").distinct\n\nusers.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/adaptivity/ml_1m/ml_users\")",
      "authenticationInfo": {},
      "dateUpdated": "Mar 30, 2017 3:15:01 PM",
      "config": {
        "enabled": true,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1490867787533_-797568296",
      "id": "20170330-115627_850679686",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "data: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\nusers: org.apache.spark.sql.DataFrame \u003d [userid: int]\n"
      },
      "dateCreated": "Mar 30, 2017 11:56:27 AM",
      "dateStarted": "Mar 30, 2017 3:15:01 PM",
      "dateFinished": "Mar 30, 2017 3:15:07 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val ml_users \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/adaptivity/ml_1m/ml_users.headers\")\n\nval ml_10_users \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/adaptivity/ml_1m/ml_10_users.headers\")\n\nval ml_remaining_90_users \u003d ml_users.select(\"userid\").except(ml_10_users.select(\"userid\")).distinct\n\nml_remaining_90_users.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/adaptivity/ml_1m/ml_remaining_90_users\")",
      "authenticationInfo": {},
      "dateUpdated": "Mar 30, 2017 3:21:15 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1490867787536_-786410578",
      "id": "20170330-115627_1873454835",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "ml_users: org.apache.spark.sql.DataFrame \u003d [userid: int]\nml_10_users: org.apache.spark.sql.DataFrame \u003d [userid: int]\nml_remaining_90_users: org.apache.spark.sql.DataFrame \u003d [userid: int]\n"
      },
      "dateCreated": "Mar 30, 2017 11:56:27 AM",
      "dateStarted": "Mar 30, 2017 3:21:15 PM",
      "dateFinished": "Mar 30, 2017 3:21:22 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val ml_users \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/adaptivity/ml_1m/ml_users.headers\")\n\nval ml_20_users \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/adaptivity/ml_1m/ml_20_users.headers\")\n\nval ml_remaining_80_users \u003d ml_users.select(\"userid\").except(ml_20_users.select(\"userid\")).distinct\n\nml_remaining_80_users.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/adaptivity/ml_1m/ml_remaining_80_users\")",
      "authenticationInfo": {},
      "dateUpdated": "Mar 30, 2017 3:25:20 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1490873201351_702534251",
      "id": "20170330-132641_856893749",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "ml_users: org.apache.spark.sql.DataFrame \u003d [userid: int]\nml_20_users: org.apache.spark.sql.DataFrame \u003d [userid: int]\nml_remaining_80_users: org.apache.spark.sql.DataFrame \u003d [userid: int]\n"
      },
      "dateCreated": "Mar 30, 2017 1:26:41 PM",
      "dateStarted": "Mar 30, 2017 3:25:20 PM",
      "dateFinished": "Mar 30, 2017 3:25:54 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val ml_users \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/adaptivity/ml_1m/ml_users.headers\")\n\n\nval ml_30_users \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/adaptivity/ml_1m/ml_30_users.headers\")\n\nval ml_remaining_70_users \u003d ml_users.select(\"userid\").except(ml_30_users.select(\"userid\")).distinct\n\nml_remaining_70_users.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/adaptivity/ml_1m/ml_remaining_70_users\")\n\n",
      "authenticationInfo": {},
      "dateUpdated": "Mar 30, 2017 3:38:50 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1490873629368_1928725707",
      "id": "20170330-133349_535349613",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "ml_users: org.apache.spark.sql.DataFrame \u003d [userid: int]\nml_30_users: org.apache.spark.sql.DataFrame \u003d [userid: int]\nml_remaining_70_users: org.apache.spark.sql.DataFrame \u003d [userid: int]\n"
      },
      "dateCreated": "Mar 30, 2017 1:33:49 PM",
      "dateStarted": "Mar 30, 2017 3:38:50 PM",
      "dateFinished": "Mar 30, 2017 3:38:57 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val ml_users \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/adaptivity/ml_1m/ml_users.headers\")\n\n\nval ml_50_users \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/adaptivity/ml_1m/ml_50_users.headers\")\n\nval ml_remaining_50_users \u003d ml_users.select(\"userid\").except(ml_50_users.select(\"userid\")).distinct\n\nml_remaining_50_users.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/adaptivity/ml_1m/ml_remaining_50_users\")",
      "authenticationInfo": {},
      "dateUpdated": "Mar 30, 2017 3:46:00 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1490880738243_1237383060",
      "id": "20170330-153218_705055585",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "ml_users: org.apache.spark.sql.DataFrame \u003d [userid: int]\nml_50_users: org.apache.spark.sql.DataFrame \u003d [userid: int]\nml_remaining_50_users: org.apache.spark.sql.DataFrame \u003d [userid: int]\n"
      },
      "dateCreated": "Mar 30, 2017 3:32:18 PM",
      "dateStarted": "Mar 30, 2017 3:46:01 PM",
      "dateFinished": "Mar 30, 2017 3:46:35 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val ml_users \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/adaptivity/ml_1m/ml_users.headers\")\n\n\nval ml_75_users \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/adaptivity/ml_1m/ml_75_users.headers\")\n\nval ml_remaining_25_users \u003d ml_users.select(\"userid\").except(ml_75_users.select(\"userid\")).distinct\n\nml_remaining_25_users.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/adaptivity/ml_1m/ml_remaining_25_users\")",
      "authenticationInfo": {},
      "dateUpdated": "Mar 30, 2017 3:54:23 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1490881560580_1831058836",
      "id": "20170330-154600_1532254239",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "ml_users: org.apache.spark.sql.DataFrame \u003d [userid: int]\nml_75_users: org.apache.spark.sql.DataFrame \u003d [userid: int]\nml_remaining_25_users: org.apache.spark.sql.DataFrame \u003d [userid: int]\n"
      },
      "dateCreated": "Mar 30, 2017 3:46:00 PM",
      "dateStarted": "Mar 30, 2017 3:54:23 PM",
      "dateFinished": "Mar 30, 2017 3:54:57 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1490881887004_470397901",
      "id": "20170330-155127_1532056525",
      "dateCreated": "Mar 30, 2017 3:51:27 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "embAdaptivity: ml_data_creation - users",
  "id": "2CCBP9VRS",
  "angularObjects": {
    "2BGHSKCA7": [],
    "2BFMBPKAB": [],
    "2BHKKP27G": [],
    "2BJHJDBK6": [],
    "2BJAQG5W4": [],
    "2BJGSXM37": [],
    "2BFXEV5XZ": [],
    "2BG77RV7M": [],
    "2BF969NNB": [],
    "2BG8QQJNC": [],
    "2BGVG5JP4": [],
    "2BJ5FCP57": [],
    "2BFEDXCTE": [],
    "2BJ8AEWCT": [],
    "2BH9AVVKH": [],
    "2BJ7KKX85": [],
    "2BHKAE8WK": [],
    "2BJ6HN5AY": []
  },
  "config": {
    "looknfeel": "default"
  },
  "info": {}
}