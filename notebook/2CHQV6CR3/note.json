{
  "paragraphs": [
    {
      "text": "val csvFileClick \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \",\")\n    .load(\"/home/ama/sidana/recsysBaselines/data/output/clicksTrainPartial\")\n \n \n",
      "dateUpdated": "May 18, 2017 1:27:45 PM",
      "config": {
        "enabled": true,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495106865291_-1896126847",
      "id": "20170518-132745_2105899278",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "csvFileClick: org.apache.spark.sql.DataFrame \u003d [userId: string, offerId: string]\n"
      },
      "dateCreated": "May 18, 2017 1:27:45 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "   val groupedInteractions \u003d csvFileClick.groupBy(\"userId\",\"offerId\").count().sort(desc(\"count\"))\n   groupedInteractions.rdd.coalesce(1, false).saveAsTextFile(\"/data/sidana/user_past_preference.csv\")",
      "dateUpdated": "May 18, 2017 1:27:45 PM",
      "config": {
        "enabled": true,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495106865291_-1896126847",
      "id": "20170518-132745_1171179139",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "groupedInteractions: org.apache.spark.sql.DataFrame \u003d [userId: string, offerId: string, count: bigint]\n"
      },
      "dateCreated": "May 18, 2017 1:27:45 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": " val countryCodes \u003d Array(\"at\",\"be\",\"br\",\"ch\",\"cz\",\"de\",\"dk\",\"es\",\"fi\",\"ie\",\"nb\",\"nl\",\"no\",\"pl\",\"pt\",\"ru\",\"se\",\"uk\",\"it\",\"fr\")\n    for (code \u003c- countryCodes){\n        val csvFileClick \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \",\")\n    .load(\"/home/ama/sidana/recsysBaselines/data/output/countryfiles/clicksTrainPartial_\"+code) \n       val groupedInteractions \u003d csvFileClick.groupBy(\"userId\",\"offerId\").count().sort(desc(\"count\"))\n   groupedInteractions.rdd.coalesce(1, false).saveAsTextFile(\"/data/sidana/recsysBaselines/pastpreferences/user_past_preference_\"+code+\".csv\")\n    }",
      "dateUpdated": "May 18, 2017 1:27:45 PM",
      "config": {
        "enabled": true,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495106865292_-1898050592",
      "id": "20170518-132745_172680771",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "countryCodes: Array[String] \u003d Array(at, be, br, ch, cz, de, dk, es, fi, ie, nb, nl, no, pl, pt, ru, se, uk, it, fr)\n"
      },
      "dateCreated": "May 18, 2017 1:27:45 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": " \n    import java.nio.file.{ Files, Paths }\n    import scala.collection.mutable.ListBuffer\n    import java.io.FileWriter\n    import org.apache.spark.sql.functions.{lit, to_date}\n    import sqlContext.implicits._\n    import org.apache.spark.sql.types._\n    import org.apache.spark.sql._\n    val countryCodes \u003d Array(\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\")\n val fwTime \u003d new FileWriter(\"/data/sidana/purch/experiments/atleast_one/online_setting/picountryfiles/output/user_past_preferences.txt\", true)\n    for (code \u003c- countryCodes){\n        val time1 \u003d java.lang.System.currentTimeMillis()\n        val csvFileClick \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/purch/experiments/atleast_one/online_setting/picountryfiles/input/train_\"+code+\".csv\")\n    \n    val clickTemp \u003d csvFileClick.filter(csvFileClick(\"rating\") \u003d\u003d\u003d\"1\")\n    \n    val groupedInteractions \u003d clickTemp.groupBy(\"userid\",\"offerid\").count().sort(desc(\"count\"))\n    groupedInteractions.rdd.coalesce(1, false).saveAsTextFile(\"/data/sidana/purch/experiments/atleast_one/online_setting/picountryfiles/output/user_past_preference_\"+code+\".csv\")\n    val time2 \u003d java.lang.System.currentTimeMillis()\n    val time \u003d time2 - time1\n    fwTime.write(code+\" \"+time)\n    }\n    fwTime.close()",
      "authenticationInfo": {},
      "dateUpdated": "May 18, 2017 1:48:38 PM",
      "config": {
        "enabled": true,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495106865292_-1898050592",
      "id": "20170518-132745_995311100",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import java.nio.file.{Files, Paths}\nimport scala.collection.mutable.ListBuffer\nimport java.io.FileWriter\nimport org.apache.spark.sql.functions.{lit, to_date}\nimport sqlContext.implicits._\nimport org.apache.spark.sql.types._\nimport org.apache.spark.sql._\ncountryCodes: Array[String] \u003d Array(36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64)\nfwTime: java.io.FileWriter \u003d java.io.FileWriter@3a66ba5c\n"
      },
      "dateCreated": "May 18, 2017 1:27:45 PM",
      "dateStarted": "May 18, 2017 1:48:38 PM",
      "dateFinished": "May 18, 2017 1:54:17 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "dateUpdated": "May 18, 2017 1:27:45 PM",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495106865292_-1898050592",
      "id": "20170518-132745_1443531217",
      "dateCreated": "May 18, 2017 1:27:45 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "purchBaselines: user_past_preferences",
  "id": "2CHQV6CR3",
  "angularObjects": {
    "2BGHSKCA7": [],
    "2BFMBPKAB": [],
    "2BHKKP27G": [],
    "2BJHJDBK6": [],
    "2BJAQG5W4": [],
    "2BJGSXM37": [],
    "2BFXEV5XZ": [],
    "2BG77RV7M": [],
    "2BF969NNB": [],
    "2BG8QQJNC": [],
    "2BGVG5JP4": [],
    "2BJ5FCP57": [],
    "2BFEDXCTE": [],
    "2BJ8AEWCT": [],
    "2BH9AVVKH": [],
    "2BJ7KKX85": [],
    "2BHKAE8WK": [],
    "2BJ6HN5AY": []
  },
  "config": {},
  "info": {}
}