{
  "paragraphs": [
    {
      "text": "//val seq \u003d Seq(\"offerid\",\"category\",\"merchant\")\n\nval candidates \u003d sqlContext.read\n.format(\"com.databricks.spark.csv\")\n.option(\"header\", \"true\") // Use first line of all files as header\n.option(\"inferSchema\", \"true\") // Automatically infer data types\n.option(\"delimiter\", \"\\t\")\n.load(\"/data/sidana/diversity/kldivergence/param_tune/all_offers_setting/wo_regularization/ml100k/test.users.unique\")\n\nval parquetFileOffers \u003d sqlContext.read\n.format(\"com.databricks.spark.csv\")\n.option(\"header\", \"true\") // Use first line of all files as header\n.option(\"inferSchema\", \"true\") // Automatically infer data types\n.option(\"delimiter\", \"\\t\")\n.load(\"/data/sidana/diversity/kldivergence/param_tune/all_offers_setting/wo_regularization/ml100k/items.unique\")\n\nval offerViews \u003d  parquetFileOffers.select(\"offerid\").distinct\n\n//val offerClicks \u003d sqlContext.read\n//.format(\"com.databricks.spark.csv\")\n//.option(\"header\", \"true\") // Use first line of all files as header\n//.option(\"inferSchema\", \"true\") // Automatically infer data types\n//.option(\"delimiter\", \",\")\n//.load(\"/data/sidana/recsysBaselines/experiments/debug_ffm/debug_ffm/debug/atleast_two/offerClicks_fr.train\").withColumnRenamed(\"count\",\"offerclickcount\")\n\n\n//val userClicks \u003d sqlContext.read\n//.format(\"com.databricks.spark.csv\")\n//.option(\"header\", \"true\") // Use first line of all files as header\n//.option(\"inferSchema\", \"true\") // Automatically infer data types\n//.option(\"delimiter\", \",\")\n//.load(\"/data/sidana/recsysBaselines/experiments/debug_ffm/debug_ffm/debug/atleast_two/userClicks_fr.train\").withColumnRenamed(\"count\",\"userclickcount\")\n\n//val offerViewsClicks \u003d offerViews.join(offerClicks,Seq(\"offerid\"),\"left_outer\")\n\nval userOfferCartesianProduct \u003d offerViews.join(candidates)\n\n//val userOfferCartesianProductClicks \u003d userOfferCartesianProduct.join(userClicks,Seq(\"userid\"),\"left_outer\").na.fill(0,Seq(\"userclickcount\",\"offerclickcount\"))\n\nval file_rating_temp \u003d userOfferCartesianProduct.withColumn(\"rating\",lit(\"0\"))\n\nval file_rating \u003d file_rating_temp.withColumn(\"timestamp\",lit(\"889396582\"))\n//val file_country \u003d file_rating.withColumn(\"countrycode\",lit(\"fr\"))\n//val file_utcdate \u003d file_country.withColumn(\"utc_date\",lit(\"x\"))\n\n\n//val tempfile \u003d file_utcdate.orderBy(\"utcdate\")\n\n//tempfile.count\n\nval header \u003d \"userid,offerid,rating,timestamp\"\n\nval selectfields \u003d file_rating.select(\"userid\",\"offerid\",\"rating\",\"timestamp\")\n\nval cartesian_product \u003d selectfields.rdd.map(_.mkString(\",\")).mapPartitionsWithIndex((i, iter) \u003d\u003e if (i\u003d\u003d0) (List(header).toIterator ++ iter) else iter)\n\ncartesian_product.coalesce(1,false).saveAsTextFile(\"/data/sidana/diversity/kldivergence/param_tune/all_offers_setting/wo_regularization/ml100k/cartesian_product\")",
      "authenticationInfo": {},
      "dateUpdated": "Jan 31, 2018 7:12:35 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1516874587687_1329899405",
      "id": "20180125-110307_1777035420",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "candidates: org.apache.spark.sql.DataFrame \u003d [userid: int]\nparquetFileOffers: org.apache.spark.sql.DataFrame \u003d [offerid: int]\nofferViews: org.apache.spark.sql.DataFrame \u003d [offerid: int]\nuserOfferCartesianProduct: org.apache.spark.sql.DataFrame \u003d [offerid: int, userid: int]\nfile_rating_temp: org.apache.spark.sql.DataFrame \u003d [offerid: int, userid: int, rating: string]\nfile_rating: org.apache.spark.sql.DataFrame \u003d [offerid: int, userid: int, rating: string, timestamp: string]\nheader: String \u003d userid,offerid,rating,timestamp\nselectfields: org.apache.spark.sql.DataFrame \u003d [userid: int, offerid: int, rating: string, timestamp: string]\ncartesian_product: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[43] at mapPartitionsWithIndex at \u003cconsole\u003e:43\n"
      },
      "dateCreated": "Jan 25, 2018 11:03:07 AM",
      "dateStarted": "Jan 31, 2018 7:12:35 PM",
      "dateFinished": "Jan 31, 2018 7:12:54 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "//val seq \u003d Seq(\"offerid\",\"category\",\"merchant\")\n\nval candidates \u003d sqlContext.read\n.format(\"com.databricks.spark.csv\")\n.option(\"header\", \"true\") // Use first line of all files as header\n.option(\"inferSchema\", \"true\") // Automatically infer data types\n.option(\"delimiter\", \"\\t\")\n.load(\"/data/sidana/diversity/kldivergence/param_tune/all_offers_setting/regularization/kasandr/test.users.unique\")\n\nval parquetFileOffers \u003d sqlContext.read\n.format(\"com.databricks.spark.csv\")\n.option(\"header\", \"true\") // Use first line of all files as header\n.option(\"inferSchema\", \"true\") // Automatically infer data types\n.option(\"delimiter\", \"\\t\")\n.load(\"/data/sidana/diversity/kldivergence/param_tune/all_offers_setting/regularization/kasandr/items.unique\")\n\nval offerViews \u003d  parquetFileOffers.select(\"offerid\").distinct\n\n//val offerClicks \u003d sqlContext.read\n//.format(\"com.databricks.spark.csv\")\n//.option(\"header\", \"true\") // Use first line of all files as header\n//.option(\"inferSchema\", \"true\") // Automatically infer data types\n//.option(\"delimiter\", \",\")\n//.load(\"/data/sidana/recsysBaselines/experiments/debug_ffm/debug_ffm/debug/atleast_two/offerClicks_fr.train\").withColumnRenamed(\"count\",\"offerclickcount\")\n\n\n//val userClicks \u003d sqlContext.read\n//.format(\"com.databricks.spark.csv\")\n//.option(\"header\", \"true\") // Use first line of all files as header\n//.option(\"inferSchema\", \"true\") // Automatically infer data types\n//.option(\"delimiter\", \",\")\n//.load(\"/data/sidana/recsysBaselines/experiments/debug_ffm/debug_ffm/debug/atleast_two/userClicks_fr.train\").withColumnRenamed(\"count\",\"userclickcount\")\n\n//val offerViewsClicks \u003d offerViews.join(offerClicks,Seq(\"offerid\"),\"left_outer\")\n\nval userOfferCartesianProduct \u003d offerViews.join(candidates)\n\n//val userOfferCartesianProductClicks \u003d userOfferCartesianProduct.join(userClicks,Seq(\"userid\"),\"left_outer\").na.fill(0,Seq(\"userclickcount\",\"offerclickcount\"))\n\nval file_rating_temp \u003d userOfferCartesianProduct.withColumn(\"rating\",lit(\"0\"))\n\nval file_rating \u003d file_rating_temp.withColumn(\"timestamp\",lit(\"889396582\"))\n//val file_country \u003d file_rating.withColumn(\"countrycode\",lit(\"fr\"))\n//val file_utcdate \u003d file_country.withColumn(\"utc_date\",lit(\"x\"))\n\n\n//val tempfile \u003d file_utcdate.orderBy(\"utcdate\")\n\n//tempfile.count\n\nval header \u003d \"userid,offerid,rating,timestamp\"\n\nval selectfields \u003d file_rating.select(\"userid\",\"offerid\",\"rating\",\"timestamp\")\n\nval cartesian_product \u003d selectfields.rdd.map(_.mkString(\",\")).mapPartitionsWithIndex((i, iter) \u003d\u003e if (i\u003d\u003d0) (List(header).toIterator ++ iter) else iter)\n\ncartesian_product.coalesce(1,false).saveAsTextFile(\"/data/sidana/diversity/kldivergence/param_tune/all_offers_setting/regularization/kasandr/cartesian_product\")",
      "authenticationInfo": {},
      "dateUpdated": "Jan 28, 2018 8:45:43 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1517167449180_-1592288183",
      "id": "20180128-202409_649287537",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "candidates: org.apache.spark.sql.DataFrame \u003d [userid: int]\nparquetFileOffers: org.apache.spark.sql.DataFrame \u003d [offerid: int]\nofferViews: org.apache.spark.sql.DataFrame \u003d [offerid: int]\nuserOfferCartesianProduct: org.apache.spark.sql.DataFrame \u003d [offerid: int, userid: int]\nfile_rating_temp: org.apache.spark.sql.DataFrame \u003d [offerid: int, userid: int, rating: string]\nfile_rating: org.apache.spark.sql.DataFrame \u003d [offerid: int, userid: int, rating: string, timestamp: string]\nheader: String \u003d userid,offerid,rating,timestamp\nselectfields: org.apache.spark.sql.DataFrame \u003d [userid: int, offerid: int, rating: string, timestamp: string]\ncartesian_product: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[34] at mapPartitionsWithIndex at \u003cconsole\u003e:43\n"
      },
      "dateCreated": "Jan 28, 2018 8:24:09 PM",
      "dateStarted": "Jan 28, 2018 8:45:43 PM",
      "dateFinished": "Jan 28, 2018 8:53:59 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "dateUpdated": "Jan 25, 2018 11:03:07 AM",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1516874587689_1327590912",
      "id": "20180125-110307_895756889",
      "dateCreated": "Jan 25, 2018 11:03:07 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "diversity: cartesian_product",
  "id": "2D587W96G",
  "angularObjects": {
    "2BJGSXM37": [],
    "2BGHSKCA7": [],
    "2BHKKP27G": [],
    "2BGVG5JP4": [],
    "2BFMBPKAB": [],
    "2BF969NNB": [],
    "2BJAQG5W4": [],
    "2BJHJDBK6": [],
    "2BHKAE8WK": [],
    "2BG8QQJNC": [],
    "2BJ7KKX85": [],
    "2BH9AVVKH": [],
    "2BJ6HN5AY": [],
    "2BFEDXCTE": [],
    "2BJ5FCP57": [],
    "2BJ8AEWCT": [],
    "2BFXEV5XZ": [],
    "2BG77RV7M": []
  },
  "config": {
    "looknfeel": "default"
  },
  "info": {}
}