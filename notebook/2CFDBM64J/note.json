{
  "paragraphs": [
    {
      "text": "val data \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/embAdaptivity/ml_1m/input_data/inputdata.headers\")\n\nval ml_10_users \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/adaptivity/ml_1m/ml_10_users.headers\")\n\nval ml_10_data_join \u003d data.join(ml_10_users,data(\"userid\")\u003d\u003d\u003dml_10_users(\"userid\")).drop(ml_10_users(\"userid\"))\n\nval ml_10_data \u003d ml_10_data_join.select(\"userid\",\"itemid\",\"rating\",\"timestamp\").orderBy(\"timestamp\")\n\nml_10_data.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/adaptivity/ml_1m/m_10_data.temp\")",
      "authenticationInfo": {},
      "dateUpdated": "Mar 30, 2017 4:12:39 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1490882744316_2041757261",
      "id": "20170330-160544_55897491",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "data: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\nml_10_users: org.apache.spark.sql.DataFrame \u003d [userid: int]\nml_10_data_join: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\nml_10_data: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\n"
      },
      "dateCreated": "Mar 30, 2017 4:05:44 PM",
      "dateStarted": "Mar 30, 2017 4:12:40 PM",
      "dateFinished": "Mar 30, 2017 4:13:47 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val data \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/embAdaptivity/ml_1m/input_data/inputdata.headers\")\n\nval ml_20_users \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/adaptivity/ml_1m/ml_20_users.headers\")\n\nval ml_20_data_join \u003d data.join(ml_20_users,data(\"userid\")\u003d\u003d\u003dml_20_users(\"userid\")).drop(ml_20_users(\"userid\"))\n\nval ml_20_data \u003d ml_20_data_join.select(\"userid\",\"itemid\",\"rating\",\"timestamp\").orderBy(\"timestamp\")\n\nml_20_data.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/adaptivity/ml_1m/m_20_data.temp\")",
      "authenticationInfo": {},
      "dateUpdated": "Mar 30, 2017 4:15:02 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1490883065806_-936723537",
      "id": "20170330-161105_325586398",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "data: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\nml_20_users: org.apache.spark.sql.DataFrame \u003d [userid: int]\nml_20_data_join: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\nml_20_data: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\n"
      },
      "dateCreated": "Mar 30, 2017 4:11:05 PM",
      "dateStarted": "Mar 30, 2017 4:15:03 PM",
      "dateFinished": "Mar 30, 2017 4:16:09 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val data \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/embAdaptivity/ml_1m/input_data/inputdata.headers\")\n\nval ml_30_users \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/adaptivity/ml_1m/ml_30_users.headers\")\n\nval ml_30_data_join \u003d data.join(ml_30_users,data(\"userid\")\u003d\u003d\u003dml_30_users(\"userid\")).drop(ml_30_users(\"userid\"))\n\nval ml_30_data \u003d ml_30_data_join.select(\"userid\",\"itemid\",\"rating\",\"timestamp\").orderBy(\"timestamp\")\n\nml_30_data.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/adaptivity/ml_1m/m_30_data.temp\")",
      "authenticationInfo": {},
      "dateUpdated": "Mar 30, 2017 4:16:22 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1490883302862_-1416572169",
      "id": "20170330-161502_486836277",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "data: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\nml_30_users: org.apache.spark.sql.DataFrame \u003d [userid: int]\nml_30_data_join: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\nml_30_data: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\n"
      },
      "dateCreated": "Mar 30, 2017 4:15:02 PM",
      "dateStarted": "Mar 30, 2017 4:16:23 PM",
      "dateFinished": "Mar 30, 2017 4:17:34 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val data \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/embAdaptivity/ml_1m/input_data/inputdata.headers\")\n\nval ml_50_users \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/adaptivity/ml_1m/ml_50_users.headers\")\n\nval ml_50_data_join \u003d data.join(ml_50_users,data(\"userid\")\u003d\u003d\u003dml_50_users(\"userid\")).drop(ml_50_users(\"userid\"))\n\nval ml_50_data \u003d ml_50_data_join.select(\"userid\",\"itemid\",\"rating\",\"timestamp\").orderBy(\"timestamp\")\n\nml_50_data.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/adaptivity/ml_1m/m_50_data.temp\")",
      "authenticationInfo": {},
      "dateUpdated": "Mar 30, 2017 4:16:51 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1490883370070_-1322015885",
      "id": "20170330-161610_1388570820",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "data: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\nml_50_users: org.apache.spark.sql.DataFrame \u003d [userid: int]\nml_50_data_join: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\nml_50_data: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\n"
      },
      "dateCreated": "Mar 30, 2017 4:16:10 PM",
      "dateStarted": "Mar 30, 2017 4:16:51 PM",
      "dateFinished": "Mar 30, 2017 4:18:08 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val data \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/embAdaptivity/ml_1m/input_data/inputdata.headers\")\n\nval ml_50_users \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/adaptivity/ml_1m/ml_50_users.headers\")\n\nval ml_50_data_join \u003d data.join(ml_50_users,data(\"userid\")\u003d\u003d\u003dml_50_users(\"userid\")).drop(ml_50_users(\"userid\"))\n\nval ml_50_data \u003d ml_50_data_join.select(\"userid\",\"itemid\",\"rating\",\"timestamp\").orderBy(\"timestamp\")\n\nml_50_data.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/adaptivity/ml_1m/m_50_data.temp\")",
      "authenticationInfo": {},
      "dateUpdated": "Mar 30, 2017 4:20:23 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1490883411334_-845049842",
      "id": "20170330-161651_653210637",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "data: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\nml_50_users: org.apache.spark.sql.DataFrame \u003d [userid: int]\nml_50_data_join: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\nml_50_data: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\n"
      },
      "dateCreated": "Mar 30, 2017 4:16:51 PM",
      "dateStarted": "Mar 30, 2017 4:20:23 PM",
      "dateFinished": "Mar 30, 2017 4:20:57 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val data \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/embAdaptivity/ml_1m/input_data/inputdata.headers\")\n\nval ml_100_users \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/adaptivity/ml_1m/ml_100_users.headers\")\n\nval ml_100_data_join \u003d data.join(ml_100_users,data(\"userid\")\u003d\u003d\u003dml_100_users(\"userid\")).drop(ml_100_users(\"userid\"))\n\nval ml_100_data \u003d ml_100_data_join.select(\"userid\",\"itemid\",\"rating\",\"timestamp\").orderBy(\"timestamp\")\n\nml_100_data.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/adaptivity/ml_1m/m_100_data.temp\")",
      "authenticationInfo": {},
      "dateUpdated": "Mar 30, 2017 4:17:36 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1490883434007_1457333549",
      "id": "20170330-161714_1965414373",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "data: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\nml_100_users: org.apache.spark.sql.DataFrame \u003d [userid: int]\nml_100_data_join: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\nml_100_data: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\n"
      },
      "dateCreated": "Mar 30, 2017 4:17:14 PM",
      "dateStarted": "Mar 30, 2017 4:18:08 PM",
      "dateFinished": "Mar 30, 2017 4:18:53 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val data \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/embAdaptivity/ml_1m/input_data/inputdata.headers\")\n\nval ml_75_users \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/data/sidana/adaptivity/ml_1m/ml_75_users.headers\")\n\nval ml_75_data_join \u003d data.join(ml_75_users,data(\"userid\")\u003d\u003d\u003dml_75_users(\"userid\")).drop(ml_75_users(\"userid\"))\n\nval ml_75_data \u003d ml_75_data_join.select(\"userid\",\"itemid\",\"rating\",\"timestamp\").orderBy(\"timestamp\")\n\nml_75_data.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/adaptivity/ml_1m/m_75_data.temp\")",
      "authenticationInfo": {},
      "dateUpdated": "Mar 30, 2017 4:24:19 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1490883456310_-878294778",
      "id": "20170330-161736_1436649125",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "data: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\nml_75_users: org.apache.spark.sql.DataFrame \u003d [userid: int]\nml_75_data_join: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\nml_75_data: org.apache.spark.sql.DataFrame \u003d [userid: int, itemid: int, rating: int, timestamp: int]\n"
      },
      "dateCreated": "Mar 30, 2017 4:17:36 PM",
      "dateStarted": "Mar 30, 2017 4:24:19 PM",
      "dateFinished": "Mar 30, 2017 4:24:50 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1490883859039_-2049671289",
      "id": "20170330-162419_1638067641",
      "dateCreated": "Mar 30, 2017 4:24:19 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "embAdaptivity: ml_data_creation - joins",
  "id": "2CFDBM64J",
  "angularObjects": {
    "2BGHSKCA7": [],
    "2BFMBPKAB": [],
    "2BHKKP27G": [],
    "2BJHJDBK6": [],
    "2BJAQG5W4": [],
    "2BJGSXM37": [],
    "2BFXEV5XZ": [],
    "2BG77RV7M": [],
    "2BF969NNB": [],
    "2BG8QQJNC": [],
    "2BGVG5JP4": [],
    "2BJ5FCP57": [],
    "2BFEDXCTE": [],
    "2BJ8AEWCT": [],
    "2BH9AVVKH": [],
    "2BJ7KKX85": [],
    "2BHKAE8WK": [],
    "2BJ6HN5AY": []
  },
  "config": {},
  "info": {}
}