{
  "paragraphs": [
    {
      "text": "val clicksTemp \u003d sqlContext.read.parquet(\"/home/ama/sidana/calypso_kk_june_data/click/fr/2016/*/*/\")\nval userClicks \u003d clicksTemp.select(clicksTemp(\"userId\"),substring_index(clicksTemp(\"offerViewId\"),\"-\",1)).withColumnRenamed(\"substring_index(offerViewId,-,1)\",\"offerIdClicks\").withColumnRenamed(\"userId\",\"userIdClicks\")\nval parquetFileOffers \u003d sqlContext.read.parquet(\"/home/ama/sidana/calypso_kk_june_data/offerView/fr/2016/*/*/\")\nval userOffers \u003d parquetFileOffers.select(parquetFileOffers(\"userId\"),substring_index(parquetFileOffers(\"offerViewId\"),\"-\",1),$\"siteDomain\".getItem(\"countryCode\"),parquetFileOffers(\"category\")(0),parquetFileOffers(\"merchant\"),parquetFileOffers(\"utcDate\")).withColumnRenamed(\"substring_index(offerViewId,-,1)\",\"offerIdOfferView\").withColumnRenamed(\"userId\",\"userIdOfferView\")\n    \n    //inner join\nval userOfferCommon \u003d userClicks.join(userOffers,userClicks(\"userIdClicks\")\u003c\u003d\u003euserOffers(\"userIdOfferView\")).drop(userClicks(\"userIdClicks\")).drop(userClicks(\"offerIdClicks\"))\n    \n    \n    //outerjoin\nval cOOuterJoin \u003d userClicks.join(userOfferCommon,userClicks(\"userIdClicks\")\u003c\u003d\u003euserOfferCommon(\"userIdOfferView\") \u0026\u0026 userClicks(\"offerIdClicks\")\u003c\u003d\u003euserOfferCommon(\"offerIdOfferView\"),\"right_outer\")\n\ncOOuterJoin.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/kelkooDataSubset/totalData_fr.csv\")\n\nfw.close()",
      "authenticationInfo": {},
      "dateUpdated": "Jan 31, 2017 4:53:20 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1485877807824_283581078",
      "id": "20170131-165007_36044411",
      "dateCreated": "Jan 31, 2017 4:50:07 PM",
      "dateStarted": "Jan 31, 2017 4:53:20 PM",
      "dateFinished": "Jan 31, 2017 5:18:09 PM",
      "status": "ERROR",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "    val clicksTempTemp \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \",\")\n    .load(\"/data/sidana/kelkooDataSubset/dat.fr\")\n    val ratings \u003d clicksTempTemp.dropDuplicates(Seq(\"userid\",\"offerid\",\"rating\"))\n    ratings.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/kelkooDataSubset/dat.fr.temp\")",
      "authenticationInfo": {},
      "dateUpdated": "Feb 1, 2017 11:30:35 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1485878000573_267314355",
      "id": "20170131-165320_2094861038",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "clicksTempTemp: org.apache.spark.sql.DataFrame \u003d [userid: string, offerid: string, rating: int, utcdate: bigint]\nratings: org.apache.spark.sql.DataFrame \u003d [userid: string, offerid: string, rating: int, utcdate: bigint]\n"
      },
      "dateCreated": "Jan 31, 2017 4:53:20 PM",
      "dateStarted": "Feb 1, 2017 11:30:35 AM",
      "dateFinished": "Feb 1, 2017 11:47:25 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val test \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \",\")\n    .load(\"/data/sidana/kelkooDataSubset/dat.fr\")\nval users \u003d test.select(\"userid\").distinct\nusers.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/kelkooDataSubset/dat.fr.users\")",
      "authenticationInfo": {},
      "dateUpdated": "Feb 1, 2017 12:13:00 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1485940189049_159070383",
      "id": "20170201-100949_1576882793",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "test: org.apache.spark.sql.DataFrame \u003d [userid: string, offerid: string, rating: int, timestamp: bigint]\nusers: org.apache.spark.sql.DataFrame \u003d [userid: string]\n"
      },
      "dateCreated": "Feb 1, 2017 10:09:49 AM",
      "dateStarted": "Feb 1, 2017 12:13:00 PM",
      "dateFinished": "Feb 1, 2017 12:16:04 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val test \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \",\")\n    .load(\"/data/sidana/kelkooDataSubset/dat.fr\")\n    \nval sampleusers \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \",\")\n    .load(\"/data/sidana/kelkooDataSubset/dat.fr.users.sample\")\n    \nval testsample \u003d test.join(sampleusers,test(\"userid\")\u003d\u003d\u003dsampleusers(\"userid\")).drop(sampleusers(\"userid\"))\n\noffers.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/kelkooDataSubset/dat.fr.offers\")\nval offers \u003d testsample.select(\"offerid\").distinct",
      "authenticationInfo": {},
      "dateUpdated": "Feb 1, 2017 12:39:10 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1485947265866_-857806462",
      "id": "20170201-120745_1954193060",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "test: org.apache.spark.sql.DataFrame \u003d [userid: string, offerid: string, rating: int, timestamp: bigint]\nsampleusers: org.apache.spark.sql.DataFrame \u003d [userid: string]\ntestsample: org.apache.spark.sql.DataFrame \u003d [userid: string, offerid: string, rating: int, timestamp: bigint]\noffers: org.apache.spark.sql.DataFrame \u003d [offerid: string]\n"
      },
      "dateCreated": "Feb 1, 2017 12:07:45 PM",
      "dateStarted": "Feb 1, 2017 12:30:40 PM",
      "dateFinished": "Feb 1, 2017 12:37:38 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val samplemovies \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \",\")\n    .load(\"/data/sidana/kelkooDataSubset/dat.fr.offers.sample\")\n\nval sample \u003d testsample.join(samplemovies,testsample(\"offerid\")\u003d\u003d\u003dsamplemovies(\"offerid\")).drop(samplemovies(\"offerid\"))\nsample.rdd.saveAsTextFile(\"/data/sidana/kelkooDataSubset/dat.fr.sample\")",
      "authenticationInfo": {},
      "dateUpdated": "Feb 1, 2017 12:45:15 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1485948561266_-456087048",
      "id": "20170201-122921_1753549954",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "samplemovies: org.apache.spark.sql.DataFrame \u003d [offerid: string]\nsample: org.apache.spark.sql.DataFrame \u003d [userid: string, offerid: string, rating: int, timestamp: bigint]\n"
      },
      "dateCreated": "Feb 1, 2017 12:29:21 PM",
      "dateStarted": "Feb 1, 2017 12:45:15 PM",
      "dateFinished": "Feb 1, 2017 12:53:11 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1485949502235_-1182748549",
      "id": "20170201-124502_306879472",
      "dateCreated": "Feb 1, 2017 12:45:02 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "kelkooDataSubset",
  "id": "2C7M5HKR2",
  "angularObjects": {
    "2BGHSKCA7": [],
    "2BFMBPKAB": [],
    "2BHKKP27G": [],
    "2BJHJDBK6": [],
    "2BJAQG5W4": [],
    "2BJGSXM37": [],
    "2BFXEV5XZ": [],
    "2BG77RV7M": [],
    "2BF969NNB": [],
    "2BG8QQJNC": [],
    "2BGVG5JP4": [],
    "2BJ5FCP57": [],
    "2BFEDXCTE": [],
    "2BJ8AEWCT": [],
    "2BH9AVVKH": [],
    "2BJ7KKX85": [],
    "2BHKAE8WK": [],
    "2BJ6HN5AY": []
  },
  "config": {},
  "info": {}
}