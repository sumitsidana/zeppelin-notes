{
  "paragraphs": [
    {
      "text": "val lengths \u003d Array(\"10\",\"20\",\"30\",\"50\",\"75\",\"100\")\n\n\t\t\t\t\tfor (length \u003c- lengths){\n    val data \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \",\")\n    .load(\"/data/sidana/adaptivity/baseline_algorithms/cofactor/outbrain/len\"+length+\"/pro/train.temp.csv\")\n    \n        val items \u003d data.select(\"sid\").distinct\n        items.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/adaptivity/baseline_algorithms/cofactor/outbrain/len\"+length+\"/pro/items\")\n    \n    \n    \n\t\t\t\t\t}",
      "authenticationInfo": {},
      "dateUpdated": "Apr 3, 2017 9:07:11 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1491221923007_2004670635",
      "id": "20170403-141843_1384958508",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "lengths: Array[String] \u003d Array(10, 20, 30, 50, 75, 100)\n"
      },
      "dateCreated": "Apr 3, 2017 2:18:43 PM",
      "dateStarted": "Apr 3, 2017 9:07:11 PM",
      "dateFinished": "Apr 3, 2017 9:07:19 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val lengths \u003d Array(\"10\",\"20\",\"30\",\"50\",\"75\",\"100\")\n\n\t\t\t\t\tfor (length \u003c- lengths){\n    val data \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \",\")\n    .load(\"/data/sidana/adaptivity/baseline_algorithms/cofactor/outbrain/len\"+length+\"/pro/train.csv\")\n    \n        val items \u003d data.select(\"sid\").distinct\n        items.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/adaptivity/baseline_algorithms/cofactor/outbrain/len\"+length+\"/pro/unique_sid.txt.temp\")\n\t\t\t\t\t}",
      "authenticationInfo": {},
      "dateUpdated": "Apr 3, 2017 9:29:35 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1491222117194_1790459087",
      "id": "20170403-142157_1195274403",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "lengths: Array[String] \u003d Array(10, 20, 30, 50, 75, 100)\n"
      },
      "dateCreated": "Apr 3, 2017 2:21:57 PM",
      "dateStarted": "Apr 3, 2017 9:29:35 PM",
      "dateFinished": "Apr 3, 2017 9:29:43 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val lengths \u003d Array(\"10\",\"20\",\"30\",\"50\",\"75\",\"100\")\n\n\t\t\tfor (length \u003c- lengths){\n    val data \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \",\")\n    .load(\"/data/sidana/adaptivity/baseline_algorithms/cofactor/outbrain/len\"+length+\"/pro/train.temp.csv\")\n    \n        val dataOrderedByTimeStamp \u003d data.orderBy(\"timestamp\")\n        \n        dataOrderedByTimeStamp.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/adaptivity/baseline_algorithms/cofactor/outbrain/len\"+length+\"/pro/train.to.temp.csv\")\n\t\t\t\t\t}",
      "authenticationInfo": {},
      "dateUpdated": "Apr 3, 2017 9:10:33 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1491223629296_1616709115",
      "id": "20170403-144709_1898669684",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "lengths: Array[String] \u003d Array(10, 20, 30, 50, 75, 100)\n"
      },
      "dateCreated": "Apr 3, 2017 2:47:09 PM",
      "dateStarted": "Apr 3, 2017 9:10:33 PM",
      "dateFinished": "Apr 3, 2017 9:10:45 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val lengths \u003d Array(\"10\",\"20\",\"30\",\"50\",\"75\",\"100\")\n\n\t\t\t\t\tfor (length \u003c- lengths){\n\t\t\t\t\t    \n    val data \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \",\")\n    .load(\"/data/sidana/adaptivity/baseline_algorithms/cofactor/outbrain/len\"+length+\"/pro/test_all.temp.csv\")\n    \n        val items \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \",\")\n    .load(\"/data/sidana/adaptivity/baseline_algorithms/cofactor/outbrain/len\"+length+\"/pro/items.txt\")\n    \n    val testdata \u003d data.join(items,data(\"sid\")\u003d\u003d\u003ditems(\"sid\")).drop(items(\"sid\"))\n    \n    val dataOrderedByTimeStamp \u003d testdata.orderBy(\"timestamp\")\n        \n    dataOrderedByTimeStamp.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/adaptivity/baseline_algorithms/cofactor/outbrain/len\"+length+\"/pro/test_all.to.temp.csv\")\n\t\t\t\t\t}",
      "authenticationInfo": {},
      "dateUpdated": "Apr 3, 2017 9:10:53 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1491225079298_-305845033",
      "id": "20170403-151119_24590837",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "lengths: Array[String] \u003d Array(10, 20, 30, 50, 75, 100)\n"
      },
      "dateCreated": "Apr 3, 2017 3:11:19 PM",
      "dateStarted": "Apr 3, 2017 9:10:53 PM",
      "dateFinished": "Apr 3, 2017 9:13:31 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val lengths \u003d Array(\"10\",\"20\",\"30\",\"50\",\"75\",\"100\")\n\n\t\t\t\t\tfor (length \u003c- lengths){\n\t\t\t\t\t    \n    val data \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \",\")\n    .load(\"/data/sidana/adaptivity/baseline_algorithms/cofactor/outbrain/len\"+length+\"/pro/test.temp.csv\")\n    \n        val items \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \",\")\n    .load(\"/data/sidana/adaptivity/baseline_algorithms/cofactor/outbrain/len\"+length+\"/pro/items.txt\")\n    \n    val testdata \u003d data.join(items,data(\"sid\")\u003d\u003d\u003ditems(\"sid\")).drop(items(\"sid\"))\n    \n    val dataOrderedByTimeStamp \u003d testdata.orderBy(\"timestamp\")\n        \n    dataOrderedByTimeStamp.rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/adaptivity/baseline_algorithms/cofactor/outbrain/len\"+length+\"/pro/test.to.temp.csv\")\n\t\t\t\t\t}",
      "authenticationInfo": {},
      "dateUpdated": "Apr 3, 2017 9:10:56 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1491228498031_1860261902",
      "id": "20170403-160818_852300424",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "lengths: Array[String] \u003d Array(10, 20, 30, 50, 75, 100)\n"
      },
      "dateCreated": "Apr 3, 2017 4:08:18 PM",
      "dateStarted": "Apr 3, 2017 9:10:56 PM",
      "dateFinished": "Apr 3, 2017 9:15:47 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val lengths \u003d Array(\"10\",\"20\",\"30\",\"50\",\"75\",\"100\")\n\n\t\t\t\t\tfor (length \u003c- lengths){\n\t\t\t\t\t    \n    val test \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \",\")\n    .load(\"/data/sidana/adaptivity/baseline_algorithms/cofactor/outbrain/len\"+length+\"/pro/test.csv\")\n    \n\n        val train \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \",\")\n    .load(\"/data/sidana/adaptivity/baseline_algorithms/cofactor/outbrain/len\"+length+\"/pro/train.csv\")\n    \n    val usersofTrain \u003d train.select(\"uid\").distinct\n    val goodtest \u003d test.join(usersofTrain,test(\"uid\") \u003d\u003d\u003d usersofTrain(\"uid\")).drop(usersofTrain(\"uid\"))\n    goodtest.orderBy(\"timestamp\").select(\"timestamp\",\"uid\",\"sid\").rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/adaptivity/baseline_algorithms/cofactor/outbrain/len\"+length+\"/pro/goodtest.csv\")\n\t\t\t\t\t}",
      "authenticationInfo": {},
      "dateUpdated": "Apr 3, 2017 10:59:26 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1491236773250_-1374492385",
      "id": "20170403-182613_533391370",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "lengths: Array[String] \u003d Array(10, 20, 30, 50, 75, 100)\n"
      },
      "dateCreated": "Apr 3, 2017 6:26:13 PM",
      "dateStarted": "Apr 3, 2017 10:59:26 PM",
      "dateFinished": "Apr 3, 2017 11:01:42 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val lengths \u003d Array(\"10\",\"20\",\"30\",\"50\",\"75\",\"100\")\n\n\t\t\t\t\tfor (length \u003c- lengths){\n\t\t\t\t\t    \n    val test \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \",\")\n    .load(\"/data/sidana/adaptivity/baseline_algorithms/cofactor/outbrain/len\"+length+\"/pro/test_all.csv\")\n    \n\n        val train \u003d sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\") // Use first line of all files as header\n    .option(\"inferSchema\", \"true\") // Automatically infer data types\n    .option(\"delimiter\", \",\")\n    .load(\"/data/sidana/adaptivity/baseline_algorithms/cofactor/outbrain/len\"+length+\"/pro/train.csv\")\n    \n    val usersofTrain \u003d train.select(\"uid\").distinct\n    val goodtest \u003d test.join(usersofTrain,test(\"uid\") \u003d\u003d\u003d usersofTrain(\"uid\")).drop(usersofTrain(\"uid\"))\n    goodtest.orderBy(\"timestamp\").select(\"timestamp\",\"uid\",\"sid\").rdd.coalesce(1,false).saveAsTextFile(\"/data/sidana/adaptivity/baseline_algorithms/cofactor/outbrain/len\"+length+\"/pro/goodtest_all.csv\")\n\t\t\t\t\t}",
      "authenticationInfo": {},
      "dateUpdated": "Apr 4, 2017 5:08:28 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1491251579968_-691531171",
      "id": "20170403-223259_969641012",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "lengths: Array[String] \u003d Array(10, 20, 30, 50, 75, 100)\n"
      },
      "dateCreated": "Apr 3, 2017 10:32:59 PM",
      "dateStarted": "Apr 4, 2017 5:08:28 AM",
      "dateFinished": "Apr 4, 2017 5:10:52 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1491275308728_-1816380415",
      "id": "20170404-050828_1697026773",
      "dateCreated": "Apr 4, 2017 5:08:28 AM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "embAdaptivity: cofactorOutbrainDatasetCreation",
  "id": "2CD69HGFY",
  "angularObjects": {
    "2BGHSKCA7": [],
    "2BFMBPKAB": [],
    "2BHKKP27G": [],
    "2BJHJDBK6": [],
    "2BJAQG5W4": [],
    "2BJGSXM37": [],
    "2BFXEV5XZ": [],
    "2BG77RV7M": [],
    "2BF969NNB": [],
    "2BG8QQJNC": [],
    "2BGVG5JP4": [],
    "2BJ5FCP57": [],
    "2BFEDXCTE": [],
    "2BJ8AEWCT": [],
    "2BH9AVVKH": [],
    "2BJ7KKX85": [],
    "2BHKAE8WK": [],
    "2BJ6HN5AY": []
  },
  "config": {},
  "info": {}
}